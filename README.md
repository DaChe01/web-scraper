# ğŸ•·ï¸ Web Scraper with Docker & MySQL  

## ğŸ“Œ Project Overview  
This project is a **web scraper** built using **Python, BeautifulSoup, and MySQL**, containerized with **Docker**. It extracts data from websites and stores it in a MySQL database.  

## ğŸš€ Features  
- Scrapes data from web pages using `BeautifulSoup`  
- Stores scraped data into a **MySQL** database  
- Fully containerized with **Docker**  
- Easy setup with a **Docker Compose** file (if included)  

## ğŸ› ï¸ Technologies Used  
- **Python** ğŸ  
- **BeautifulSoup** ğŸŒ  
- **MySQL** ğŸ“„  
- **Docker** ğŸ³  

## ğŸ‘¤ Project Structure  
```plaintext
ğŸ“‚ web-scraper/
â”œâ”€â”€ ğŸ“„ Dockerfile        # Docker setup for the web scraper
â”œâ”€â”€ ğŸ“„ requirements.txt  # Python dependencies
â”œâ”€â”€ ğŸ“„ web_scraper.py    # Main web scraping script
â”œâ”€â”€ ğŸ“„ .gitignore        # Files to ignore in Git
â””â”€â”€ ğŸ“„ README.md         # Project documentation
```

## âš™ï¸ Installation & Setup  

### 1ï¸âƒ£ **Clone the Repository**  
```bash
git clone https://github.com/DaChe01/web-scraper.git
cd web-scraper
```

### 2ï¸âƒ£ **Build the Docker Image**  
```bash
docker build -t web-scraper .
```

### 3ï¸âƒ£ **Run the MySQL Container**  
```bash
docker run -dit --name mysql_db -e MYSQL_ROOT_PASSWORD=mypassword -e MYSQL_DATABASE=web_scraper -e MYSQL_PASSWORD=mypassword mysql
```

### 4ï¸âƒ£ **Run the Web Scraper in a Container**  
```bash
docker run --rm --name scraper-container --link mysql_db:mysql web-scraper
```

## ğŸ›‹ï¸ Environment Variables (Optional)  
You can configure database credentials via `.env` or pass them during `docker run`.  

## ğŸ—ƒï¸ Future Improvements  
- [ ] Add support for **Scrapy**  
- [ ] Implement a **REST API** for managing scraped data  
- [ ] Store data in **CSV/JSON** as an option  

